{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Representation - doc2vec (paragraph vector)\n",
    "문서(document), 문단(paragraph), 또는 문장(sentence)를 Continuous vector로 표현하는 방법인 doc2vec(paragraph vector)를 해봅니다. paragraph vector model은 PV-DM, PV-DBOW가 있고, 본 노트에서는 PV-DM만 모두 구현합니다. arXiv에서 scraping한 text mining 관련 논문의 초록의 단어들로 진행합니다. 상세한 내용은 아래의 논문을 참고하시길 바랍니다.\n",
    "  \n",
    "* _nltk를 활용합니다._\n",
    "* gensim을 활용합니다.\n",
    "* nltk : http://www.nltk.org/book/\n",
    "* gensim : https://radimrehurek.com/gensim/index.html\n",
    "* 논문 : http://proceedings.mlr.press/v32/le14.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec\n",
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Distributed Representation (doc2vec or paragraph vector).ipynb',\n",
       " 'Distributed Representation (word2vec).ipynb',\n",
       " 'Document Representation (term frequency, tf-idf).ipynb',\n",
       " 'Scrapping text mining papers in arXiv.py',\n",
       " 'Simple NLP for English.ipynb',\n",
       " 'Simple NLP for Korean.ipynb',\n",
       " 'text_mining_paper.csv']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load abstracts of text mining papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>author</th>\n",
       "      <th>meta</th>\n",
       "      <th>subject</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The complicated, evolving landscape of cancer ...</td>\n",
       "      <td>Rocco Piazza, Daniele Ramazzotti, Roberta Spin...</td>\n",
       "      <td>Thu, 9 Mar 2017 01:24:23 GMT (948kb)</td>\n",
       "      <td>Genomics (q-bio.GN)</td>\n",
       "      <td>OncoScore: a novel, Internet-based tool to ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mining textual patterns in news, tweets, paper...</td>\n",
       "      <td>Meng Jiang, Jingbo Shang, Taylor Cassidy, Xian...</td>\n",
       "      <td>Mon, 13 Mar 2017 01:06:19 GMT (1150kb,D) [v2] ...</td>\n",
       "      <td>Computation and Language (cs.CL)</td>\n",
       "      <td>MetaPAD: Meta Pattern Discovery from Massive T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This paper is a tutorial on Formal Concept Ana...</td>\n",
       "      <td>Dmitry I. Ignatov</td>\n",
       "      <td>Wed, 8 Mar 2017 12:53:21 GMT (3541kb,D)</td>\n",
       "      <td>Information Retrieval (cs.IR)</td>\n",
       "      <td>Introduction to Formal Concept Analysis and It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Topic models have been widely used in discover...</td>\n",
       "      <td>Jarvan Law, Hankz Hankui Zhuo, Junhua He, Erhu...</td>\n",
       "      <td>Thu, 23 Feb 2017 07:16:03 GMT (96kb,D)</td>\n",
       "      <td>Computation and Language (cs.CL)</td>\n",
       "      <td>LTSG: Latent Topical Skip-Gram for Mutually Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Entity extraction is fundamental to many text ...</td>\n",
       "      <td>Zeyi Wen, Dong Deng, Rui Zhang, Kotagiri Ramam...</td>\n",
       "      <td>Sun, 12 Feb 2017 12:46:40 GMT (89kb)</td>\n",
       "      <td>Databases (cs.DB)</td>\n",
       "      <td>A Technical Report: Entity Extraction using Bo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  \\\n",
       "0  The complicated, evolving landscape of cancer ...   \n",
       "1  Mining textual patterns in news, tweets, paper...   \n",
       "2  This paper is a tutorial on Formal Concept Ana...   \n",
       "3  Topic models have been widely used in discover...   \n",
       "4  Entity extraction is fundamental to many text ...   \n",
       "\n",
       "                                              author  \\\n",
       "0  Rocco Piazza, Daniele Ramazzotti, Roberta Spin...   \n",
       "1  Meng Jiang, Jingbo Shang, Taylor Cassidy, Xian...   \n",
       "2                                  Dmitry I. Ignatov   \n",
       "3  Jarvan Law, Hankz Hankui Zhuo, Junhua He, Erhu...   \n",
       "4  Zeyi Wen, Dong Deng, Rui Zhang, Kotagiri Ramam...   \n",
       "\n",
       "                                                meta  \\\n",
       "0               Thu, 9 Mar 2017 01:24:23 GMT (948kb)   \n",
       "1  Mon, 13 Mar 2017 01:06:19 GMT (1150kb,D) [v2] ...   \n",
       "2            Wed, 8 Mar 2017 12:53:21 GMT (3541kb,D)   \n",
       "3             Thu, 23 Feb 2017 07:16:03 GMT (96kb,D)   \n",
       "4               Sun, 12 Feb 2017 12:46:40 GMT (89kb)   \n",
       "\n",
       "                            subject  \\\n",
       "0               Genomics (q-bio.GN)   \n",
       "1  Computation and Language (cs.CL)   \n",
       "2     Information Retrieval (cs.IR)   \n",
       "3  Computation and Language (cs.CL)   \n",
       "4                 Databases (cs.DB)   \n",
       "\n",
       "                                               title  \n",
       "0  OncoScore: a novel, Internet-based tool to ass...  \n",
       "1  MetaPAD: Meta Pattern Discovery from Massive T...  \n",
       "2  Introduction to Formal Concept Analysis and It...  \n",
       "3  LTSG: Latent Topical Skip-Gram for Mutually Le...  \n",
       "4  A Technical Report: Entity Extraction using Bo...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers = pd.read_csv('./text_mining_paper.csv', encoding = 'cp949')\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abstracts = list(papers['abstract'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "1. 2글자 이상의 영단어 추출, 모두 소문자로 변환\n",
    "2. gensim의 Doc2Vec class가 input으로 받을 수 있는 corpus 형태로 변환  \n",
    "(collections module의 namedtuple 이용)\n",
    "\n",
    "참고 : http://stackoverflow.com/questions/31321209/doc2vec-how-to-get-document-vectors  \n",
    "참고 : https://radimrehurek.com/gensim/models/doc2vec.html#tutorial  \n",
    "참고 : https://www.lucypark.kr/slides/2015-pyconkr/#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = list(map(lambda x : re.findall('[A-z]{2,}',x.lower()), abstracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', ['words', 'tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['the', 'complicated', 'evolving', 'landscape', 'of', 'cancer', 'mutations', 'poses', 'formidable', 'challenge', 'to', 'identify', 'cancer', 'genes', 'among', 'the', 'large', 'lists', 'of', 'mutations', 'typically', 'generated', 'in', 'ngs', 'experiments', 'the', 'ability', 'to', 'prioritize', 'these', 'variants', 'is', 'therefore', 'of', 'paramount', 'importance', 'to', 'address', 'this', 'issue', 'we', 'developed', 'oncoscore', 'text', 'mining', 'tool', 'that', 'ranks', 'genes', 'according', 'to', 'their', 'association', 'with', 'cancer', 'based', 'on', 'available', 'biomedical', 'literature', 'receiver', 'operating', 'characteristic', 'curve', 'and', 'the', 'area', 'under', 'the', 'curve', 'auc', 'metrics', 'on', 'manually', 'curated', 'datasets', 'confirmed', 'the', 'excellent', 'discriminating', 'capability', 'of', 'oncoscore', 'oncoscore', 'cut', 'off', 'threshold', 'auc', 'ci', 'indicating', 'that', 'oncoscore', 'provides', 'useful', 'results', 'in', 'cases', 'where', 'an', 'efficient', 'prioritization', 'of', 'cancer', 'associated', 'genes', 'is', 'needed'], tags=[0]),\n",
       " TaggedDocument(words=['mining', 'textual', 'patterns', 'in', 'news', 'tweets', 'papers', 'and', 'many', 'other', 'kinds', 'of', 'text', 'corpora', 'has', 'been', 'an', 'active', 'theme', 'in', 'text', 'mining', 'and', 'nlp', 'research', 'previous', 'studies', 'adopt', 'dependency', 'parsing', 'based', 'pattern', 'discovery', 'approach', 'however', 'the', 'parsing', 'results', 'lose', 'rich', 'context', 'around', 'entities', 'in', 'the', 'patterns', 'and', 'the', 'process', 'is', 'costly', 'for', 'corpus', 'of', 'large', 'scale', 'in', 'this', 'study', 'we', 'propose', 'novel', 'typed', 'textual', 'pattern', 'structure', 'called', 'meta', 'pattern', 'which', 'is', 'extended', 'to', 'frequent', 'informative', 'and', 'precise', 'subsequence', 'pattern', 'in', 'certain', 'context', 'we', 'propose', 'an', 'efficient', 'framework', 'called', 'metapad', 'which', 'discovers', 'meta', 'patterns', 'from', 'massive', 'corpora', 'with', 'three', 'techniques', 'it', 'develops', 'context', 'aware', 'segmentation', 'method', 'to', 'carefully', 'determine', 'the', 'boundaries', 'of', 'patterns', 'with', 'learnt', 'pattern', 'quality', 'assessment', 'function', 'which', 'avoids', 'costly', 'dependency', 'parsing', 'and', 'generates', 'high', 'quality', 'patterns', 'it', 'identifies', 'and', 'groups', 'synonymous', 'meta', 'patterns', 'from', 'multiple', 'facets', 'their', 'types', 'contexts', 'and', 'extractions', 'and', 'it', 'examines', 'type', 'distributions', 'of', 'entities', 'in', 'the', 'instances', 'extracted', 'by', 'each', 'group', 'of', 'patterns', 'and', 'looks', 'for', 'appropriate', 'type', 'levels', 'to', 'make', 'discovered', 'patterns', 'precise', 'experiments', 'demonstrate', 'that', 'our', 'proposed', 'framework', 'discovers', 'high', 'quality', 'typed', 'textual', 'patterns', 'efficiently', 'from', 'different', 'genres', 'of', 'massive', 'corpora', 'and', 'facilitates', 'information', 'extraction'], tags=[1])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_train_docs = [TaggedDocument(words, [tags]) for tags, words in enumerate(corpus)]\n",
    "tagged_train_docs[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training doc2vec\n",
    "관련하여 자세한 옵션은 공식 문서를 참조할 것, 본 예제에서는 다음과 같은 parameter로 training  \n",
    "참고 : https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "1. *size = 100* : 100차원의 벡터로 embedding (document와 word 모두, 이 때의 word embedding이 word2vec과 같은 효과를 가지는 지는 검증이 필요)\n",
    "2. *dm = 1*: pv-dm (paragraph vector : distributed memory)\n",
    "3. *dm_concat = 1* : 1-layer의 hidden node의 값들을 구성할 때, word vector와 paragraph vector concatenate 함  \n",
    "   (논문 상에서 average 보다 concatenate가 성능이 더 좋다고 말하고 있음.)\n",
    "4. *min_count = 2* : 최소 2회이상 나타난 단어만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import doc2vec\n",
    "# 사전 구축\n",
    "config = {'size' : 100, 'dm_concat' : 1, 'dm' : 1, 'min_count' : 2}\n",
    "doc_vectorizer = doc2vec.Doc2Vec(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train document vectors!\n",
    "doc_vectorizer.build_vocab(tagged_train_docs)\n",
    "for epoch in range(100):\n",
    "    doc_vectorizer.train(tagged_train_docs)\n",
    "    doc_vectorizer.alpha -= 0.002  # decrease the learning rate\n",
    "    doc_vectorizer.min_alpha = doc_vectorizer.alpha  # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Documnet Embedding\n",
    "np.asarray(doc_vectorizer.docvecs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Word Embedding\n",
    "my_word = doc_vectorizer.wv.index2word\n",
    "word_embedding = [doc_vectorizer.wv[token] for token in my_word]\n",
    "word_embedding = np.asarray(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2214, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedding.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
